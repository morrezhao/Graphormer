{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"metadata":{}},"outputs":[],"source":["import numpy as np\n","\n","def generate_electrons(n_electrons, n_groups):\n","    # 生成每个群的随机三维坐标以及电荷，目前默认电子所以电荷数都是1.\n","    # 使用下面那一行注释内容就可以把电荷数扩充到1-10之间的随机数\n","    positions = np.random.randn(n_groups, n_electrons, 3)\n","    charges = -np.ones((n_groups, n_electrons), dtype=int)  # 每个电子带负电\n","    # charges = -np.random.randint(1, 11, size=(n_groups, n_electrons))  # 每个电子带负电1-10\n","    return positions, charges\n","\n","\n","def calculate_forces_and_potential(positions, charges):\n","    k_e = 1  # 库伦常数，用了原子单位制\n","    n_groups, n_electrons, _ = positions.shape\n","    forces = np.zeros_like(positions)\n","    potential_energy = np.zeros(n_groups, dtype=np.float32)\n","\n","    for group in range(n_groups):\n","        for i in range(n_electrons):\n","            for j in range(i + 1, n_electrons):\n","                r_vec = positions[group, j] - positions[group, i]\n","                r_mag = np.linalg.norm(r_vec)\n","                if r_mag == 0:\n","                    continue  # 避免两个随机出来的坐标恰好完全相同\n","                r_hat = r_vec / r_mag\n","\n","                force_magnitude = k_e * charges[group, i] * charges[group, j] / r_mag ** 2\n","                forces[group, i] -= force_magnitude * r_hat\n","                forces[group, j] += force_magnitude * r_hat\n","                potential_energy[group] += k_e * charges[group, i] * charges[group, j] / r_mag\n","\n","    return forces, potential_energy\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"metadata":{}},"outputs":[],"source":["import torch\n","\n","n_electrons = 5  # 每个电子群中的电子数量\n","n_groups = 10  # 生成10个电子群\n","\n","# device = 'cpu'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","positions, charges = generate_electrons(n_electrons, n_groups)\n","forces, potential_energy = calculate_forces_and_potential(positions, charges)\n","potential_energy = torch.from_numpy(potential_energy)\n","positions_tensor = torch.from_numpy(positions).to(device=device)\n","padding_tensor = torch.zeros((n_groups, 1, 3), device=device)\n","positions_tensor = torch.cat([padding_tensor, positions_tensor], dim=1)\n","positions_tensor.requires_grad = True\n","\n","# 这里用来生成和处理数据"]},{"cell_type":"code","execution_count":22,"metadata":{"metadata":{}},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of GraphormerModel were not initialized from the model checkpoint at clefourrier/graphormer-base-pcqm4mv1 and are newly initialized: ['graph_encoder.emb_layer_norm.bias', 'graph_encoder.emb_layer_norm.weight', 'graph_encoder.graph_attn_bias.edge_dis_encoder.weight', 'graph_encoder.graph_attn_bias.edge_encoder.weight', 'graph_encoder.graph_attn_bias.graph_token_virtual_distance.weight', 'graph_encoder.graph_attn_bias.spatial_pos_encoder.weight', 'graph_encoder.graph_node_feature.atom_encoder.weight', 'graph_encoder.graph_node_feature.graph_token.weight', 'graph_encoder.graph_node_feature.in_degree_encoder.weight', 'graph_encoder.graph_node_feature.out_degree_encoder.weight', 'graph_encoder.layers.0.fc1.bias', 'graph_encoder.layers.0.fc1.weight', 'graph_encoder.layers.0.fc2.bias', 'graph_encoder.layers.0.fc2.weight', 'graph_encoder.layers.0.final_layer_norm.bias', 'graph_encoder.layers.0.final_layer_norm.weight', 'graph_encoder.layers.0.self_attn.k_proj.bias', 'graph_encoder.layers.0.self_attn.k_proj.weight', 'graph_encoder.layers.0.self_attn.out_proj.bias', 'graph_encoder.layers.0.self_attn.out_proj.weight', 'graph_encoder.layers.0.self_attn.q_proj.bias', 'graph_encoder.layers.0.self_attn.q_proj.weight', 'graph_encoder.layers.0.self_attn.v_proj.bias', 'graph_encoder.layers.0.self_attn.v_proj.weight', 'graph_encoder.layers.0.self_attn_layer_norm.bias', 'graph_encoder.layers.0.self_attn_layer_norm.weight', 'graph_encoder.layers.1.fc1.bias', 'graph_encoder.layers.1.fc1.weight', 'graph_encoder.layers.1.fc2.bias', 'graph_encoder.layers.1.fc2.weight', 'graph_encoder.layers.1.final_layer_norm.bias', 'graph_encoder.layers.1.final_layer_norm.weight', 'graph_encoder.layers.1.self_attn.k_proj.bias', 'graph_encoder.layers.1.self_attn.k_proj.weight', 'graph_encoder.layers.1.self_attn.out_proj.bias', 'graph_encoder.layers.1.self_attn.out_proj.weight', 'graph_encoder.layers.1.self_attn.q_proj.bias', 'graph_encoder.layers.1.self_attn.q_proj.weight', 'graph_encoder.layers.1.self_attn.v_proj.bias', 'graph_encoder.layers.1.self_attn.v_proj.weight', 'graph_encoder.layers.1.self_attn_layer_norm.bias', 'graph_encoder.layers.1.self_attn_layer_norm.weight', 'graph_encoder.layers.10.fc1.bias', 'graph_encoder.layers.10.fc1.weight', 'graph_encoder.layers.10.fc2.bias', 'graph_encoder.layers.10.fc2.weight', 'graph_encoder.layers.10.final_layer_norm.bias', 'graph_encoder.layers.10.final_layer_norm.weight', 'graph_encoder.layers.10.self_attn.k_proj.bias', 'graph_encoder.layers.10.self_attn.k_proj.weight', 'graph_encoder.layers.10.self_attn.out_proj.bias', 'graph_encoder.layers.10.self_attn.out_proj.weight', 'graph_encoder.layers.10.self_attn.q_proj.bias', 'graph_encoder.layers.10.self_attn.q_proj.weight', 'graph_encoder.layers.10.self_attn.v_proj.bias', 'graph_encoder.layers.10.self_attn.v_proj.weight', 'graph_encoder.layers.10.self_attn_layer_norm.bias', 'graph_encoder.layers.10.self_attn_layer_norm.weight', 'graph_encoder.layers.11.fc1.bias', 'graph_encoder.layers.11.fc1.weight', 'graph_encoder.layers.11.fc2.bias', 'graph_encoder.layers.11.fc2.weight', 'graph_encoder.layers.11.final_layer_norm.bias', 'graph_encoder.layers.11.final_layer_norm.weight', 'graph_encoder.layers.11.self_attn.k_proj.bias', 'graph_encoder.layers.11.self_attn.k_proj.weight', 'graph_encoder.layers.11.self_attn.out_proj.bias', 'graph_encoder.layers.11.self_attn.out_proj.weight', 'graph_encoder.layers.11.self_attn.q_proj.bias', 'graph_encoder.layers.11.self_attn.q_proj.weight', 'graph_encoder.layers.11.self_attn.v_proj.bias', 'graph_encoder.layers.11.self_attn.v_proj.weight', 'graph_encoder.layers.11.self_attn_layer_norm.bias', 'graph_encoder.layers.11.self_attn_layer_norm.weight', 'graph_encoder.layers.2.fc1.bias', 'graph_encoder.layers.2.fc1.weight', 'graph_encoder.layers.2.fc2.bias', 'graph_encoder.layers.2.fc2.weight', 'graph_encoder.layers.2.final_layer_norm.bias', 'graph_encoder.layers.2.final_layer_norm.weight', 'graph_encoder.layers.2.self_attn.k_proj.bias', 'graph_encoder.layers.2.self_attn.k_proj.weight', 'graph_encoder.layers.2.self_attn.out_proj.bias', 'graph_encoder.layers.2.self_attn.out_proj.weight', 'graph_encoder.layers.2.self_attn.q_proj.bias', 'graph_encoder.layers.2.self_attn.q_proj.weight', 'graph_encoder.layers.2.self_attn.v_proj.bias', 'graph_encoder.layers.2.self_attn.v_proj.weight', 'graph_encoder.layers.2.self_attn_layer_norm.bias', 'graph_encoder.layers.2.self_attn_layer_norm.weight', 'graph_encoder.layers.3.fc1.bias', 'graph_encoder.layers.3.fc1.weight', 'graph_encoder.layers.3.fc2.bias', 'graph_encoder.layers.3.fc2.weight', 'graph_encoder.layers.3.final_layer_norm.bias', 'graph_encoder.layers.3.final_layer_norm.weight', 'graph_encoder.layers.3.self_attn.k_proj.bias', 'graph_encoder.layers.3.self_attn.k_proj.weight', 'graph_encoder.layers.3.self_attn.out_proj.bias', 'graph_encoder.layers.3.self_attn.out_proj.weight', 'graph_encoder.layers.3.self_attn.q_proj.bias', 'graph_encoder.layers.3.self_attn.q_proj.weight', 'graph_encoder.layers.3.self_attn.v_proj.bias', 'graph_encoder.layers.3.self_attn.v_proj.weight', 'graph_encoder.layers.3.self_attn_layer_norm.bias', 'graph_encoder.layers.3.self_attn_layer_norm.weight', 'graph_encoder.layers.4.fc1.bias', 'graph_encoder.layers.4.fc1.weight', 'graph_encoder.layers.4.fc2.bias', 'graph_encoder.layers.4.fc2.weight', 'graph_encoder.layers.4.final_layer_norm.bias', 'graph_encoder.layers.4.final_layer_norm.weight', 'graph_encoder.layers.4.self_attn.k_proj.bias', 'graph_encoder.layers.4.self_attn.k_proj.weight', 'graph_encoder.layers.4.self_attn.out_proj.bias', 'graph_encoder.layers.4.self_attn.out_proj.weight', 'graph_encoder.layers.4.self_attn.q_proj.bias', 'graph_encoder.layers.4.self_attn.q_proj.weight', 'graph_encoder.layers.4.self_attn.v_proj.bias', 'graph_encoder.layers.4.self_attn.v_proj.weight', 'graph_encoder.layers.4.self_attn_layer_norm.bias', 'graph_encoder.layers.4.self_attn_layer_norm.weight', 'graph_encoder.layers.5.fc1.bias', 'graph_encoder.layers.5.fc1.weight', 'graph_encoder.layers.5.fc2.bias', 'graph_encoder.layers.5.fc2.weight', 'graph_encoder.layers.5.final_layer_norm.bias', 'graph_encoder.layers.5.final_layer_norm.weight', 'graph_encoder.layers.5.self_attn.k_proj.bias', 'graph_encoder.layers.5.self_attn.k_proj.weight', 'graph_encoder.layers.5.self_attn.out_proj.bias', 'graph_encoder.layers.5.self_attn.out_proj.weight', 'graph_encoder.layers.5.self_attn.q_proj.bias', 'graph_encoder.layers.5.self_attn.q_proj.weight', 'graph_encoder.layers.5.self_attn.v_proj.bias', 'graph_encoder.layers.5.self_attn.v_proj.weight', 'graph_encoder.layers.5.self_attn_layer_norm.bias', 'graph_encoder.layers.5.self_attn_layer_norm.weight', 'graph_encoder.layers.6.fc1.bias', 'graph_encoder.layers.6.fc1.weight', 'graph_encoder.layers.6.fc2.bias', 'graph_encoder.layers.6.fc2.weight', 'graph_encoder.layers.6.final_layer_norm.bias', 'graph_encoder.layers.6.final_layer_norm.weight', 'graph_encoder.layers.6.self_attn.k_proj.bias', 'graph_encoder.layers.6.self_attn.k_proj.weight', 'graph_encoder.layers.6.self_attn.out_proj.bias', 'graph_encoder.layers.6.self_attn.out_proj.weight', 'graph_encoder.layers.6.self_attn.q_proj.bias', 'graph_encoder.layers.6.self_attn.q_proj.weight', 'graph_encoder.layers.6.self_attn.v_proj.bias', 'graph_encoder.layers.6.self_attn.v_proj.weight', 'graph_encoder.layers.6.self_attn_layer_norm.bias', 'graph_encoder.layers.6.self_attn_layer_norm.weight', 'graph_encoder.layers.7.fc1.bias', 'graph_encoder.layers.7.fc1.weight', 'graph_encoder.layers.7.fc2.bias', 'graph_encoder.layers.7.fc2.weight', 'graph_encoder.layers.7.final_layer_norm.bias', 'graph_encoder.layers.7.final_layer_norm.weight', 'graph_encoder.layers.7.self_attn.k_proj.bias', 'graph_encoder.layers.7.self_attn.k_proj.weight', 'graph_encoder.layers.7.self_attn.out_proj.bias', 'graph_encoder.layers.7.self_attn.out_proj.weight', 'graph_encoder.layers.7.self_attn.q_proj.bias', 'graph_encoder.layers.7.self_attn.q_proj.weight', 'graph_encoder.layers.7.self_attn.v_proj.bias', 'graph_encoder.layers.7.self_attn.v_proj.weight', 'graph_encoder.layers.7.self_attn_layer_norm.bias', 'graph_encoder.layers.7.self_attn_layer_norm.weight', 'graph_encoder.layers.8.fc1.bias', 'graph_encoder.layers.8.fc1.weight', 'graph_encoder.layers.8.fc2.bias', 'graph_encoder.layers.8.fc2.weight', 'graph_encoder.layers.8.final_layer_norm.bias', 'graph_encoder.layers.8.final_layer_norm.weight', 'graph_encoder.layers.8.self_attn.k_proj.bias', 'graph_encoder.layers.8.self_attn.k_proj.weight', 'graph_encoder.layers.8.self_attn.out_proj.bias', 'graph_encoder.layers.8.self_attn.out_proj.weight', 'graph_encoder.layers.8.self_attn.q_proj.bias', 'graph_encoder.layers.8.self_attn.q_proj.weight', 'graph_encoder.layers.8.self_attn.v_proj.bias', 'graph_encoder.layers.8.self_attn.v_proj.weight', 'graph_encoder.layers.8.self_attn_layer_norm.bias', 'graph_encoder.layers.8.self_attn_layer_norm.weight', 'graph_encoder.layers.9.fc1.bias', 'graph_encoder.layers.9.fc1.weight', 'graph_encoder.layers.9.fc2.bias', 'graph_encoder.layers.9.fc2.weight', 'graph_encoder.layers.9.final_layer_norm.bias', 'graph_encoder.layers.9.final_layer_norm.weight', 'graph_encoder.layers.9.self_attn.k_proj.bias', 'graph_encoder.layers.9.self_attn.k_proj.weight', 'graph_encoder.layers.9.self_attn.out_proj.bias', 'graph_encoder.layers.9.self_attn.out_proj.weight', 'graph_encoder.layers.9.self_attn.q_proj.bias', 'graph_encoder.layers.9.self_attn.q_proj.weight', 'graph_encoder.layers.9.self_attn.v_proj.bias', 'graph_encoder.layers.9.self_attn.v_proj.weight', 'graph_encoder.layers.9.self_attn_layer_norm.bias', 'graph_encoder.layers.9.self_attn_layer_norm.weight', 'layer_norm.bias', 'layer_norm.weight', 'lm_head_transform_weight.bias', 'lm_head_transform_weight.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# 使用预定义的模型，为了简化，multi_hop_max_dist取0\n","# 如果使用的不是dp的服务器，请注释掉os.environ这两行\n","from transformers import GraphormerModel, AdamW, GraphormerConfig\n","import os\n","\n","###\n","os.environ['HTTP_PROXY'] = 'http://ga.dp.tech:8118'\n","os.environ['HTTPS_PROXY'] = 'http://ga.dp.tech:8118'\n","###\n","\n","model_name = \"clefourrier/graphormer-base-pcqm4mv1\"\n","\n","backbone_model = GraphormerModel.from_pretrained(model_name)\n","config = GraphormerConfig.from_pretrained(model_name)\n","config.multi_hop_max_dist = 0"]},{"cell_type":"code","execution_count":23,"metadata":{"metadata":{}},"outputs":[],"source":["from transformers import GraphormerModel\n","import torch\n","import torch.nn as nn\n","\n","# 定义新的注意力头，用于预测势能\n","\n","class CustomGraphormerModel(nn.Module):\n","    def __init__(self, graphormer_model):\n","        super().__init__()\n","        self.graphormer = graphormer_model\n","        # self.force_head = nn.Linear(768, 3)  # 输出力的线性层，假设每个原子有三个力分量\n","        self.energy_head = nn.Linear(768, 1)  # 输出势能的线性层\n","    \n","    def convert_to_inputs(self, positions):\n","        n_groups, n_electrons, _ = positions.shape\n","        # 这是因为graphormer引入了一个虚节点，position[:, 0]都是占位符[0, 0, 0]，是没有任何意义的，所以force[:,1:]才有意义。真实的电子数是positions.shape[1]-1\n","        n_electrons -= 1\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","        # （服务器内存好像不太够，先用cpu了）\n","        # device = 'cpu'\n","\n","        # 初始化Tensor\n","        # input_nodes = torch.ones((n_groups, n_electrons, 1), device=device, dtype=int)  # [num_graphs, num_nodes, 1]\n","        input_nodes = -torch.from_numpy(charges).unsqueeze(-1).to(device=device)\n","        input_edges = torch.zeros((n_groups, n_electrons, n_electrons, 1, 1), device=device, dtype=int) # [num_graphs, num_nodes, num_nodes, max_hop, num_edge_features]\n","        # attn_bias = torch.zeros((n_groups, n_electrons + 1, n_electrons + 1), device=device)  \n","        in_degree = torch.ones((n_groups, n_electrons), device=device, dtype=int) * (n_electrons - 1)\n","        out_degree = torch.ones((n_groups, n_electrons), device=device, dtype=int) * (n_electrons - 1)\n","        spatial_pos = torch.zeros((n_groups, n_electrons, n_electrons), device=device, dtype=int)  \n","        # spatial_pos = torch.arange(n_electrons).unsqueeze(0).repeat(n_groups, 1).to(device)\n","        attn_edge_type = torch.zeros((n_groups, n_electrons, n_electrons), device=device, dtype=int)\n","\n","        # 计算边特征为距离的倒数\n","        for group in range(n_groups):\n","            for i in range(n_electrons):\n","                for j in range(n_electrons):\n","                    if i != j:\n","                        # distance = torch.norm(positions[group, i] - positions[group, j])\n","                        # attn_bias[group, i + 1, j + 1] = distance\n","                        input_edges[group, i, j, 0, 0] = 1\n","                        spatial_pos[group, i, j] = 1\n","        expanded_positions_i = positions.unsqueeze(2).repeat(1, 1, n_electrons + 1, 1)\n","        expanded_positions_j = positions.unsqueeze(1).repeat(1, n_electrons + 1, 1, 1)\n","        # print(expanded_positions_i.shape, expanded_positions_j.shape)\n","\n","    # 计算所有配对的欧几里得距离\n","        attn_bias = torch.norm(expanded_positions_i - expanded_positions_j, dim=3)\n","        # print(\"positions_grad:\", torch.autograd.grad(attn_bias[0][1][2], positions, create_graph=True)[0])\n","\n","        graphormer_inputs = {\n","            'input_nodes': input_nodes,\n","            'input_edges': input_edges,\n","            'attn_bias': attn_bias,\n","            'in_degree': in_degree,\n","            'out_degree': out_degree,\n","            'spatial_pos': spatial_pos,\n","            'attn_edge_type': attn_edge_type\n","        }\n","        \n","        return graphormer_inputs\n","\n","    def forward(self, positions):\n","        inputs = self.convert_to_inputs(positions=positions)\n","        outputs = self.graphormer(**inputs)\n","        pooled_output = outputs.last_hidden_state.mean(dim=1)  # 从Graphormer输出中提取池化表示\n","        # forces = self.force_head(pooled_output)  # 预测力  \n","        energy = self.energy_head(pooled_output)  # 预测势能\n","        # forces_1 = torch.zeros_like(positions)\n","        # print(torch.autograd.grad(energy[0], self.positions, create_graph=True, allow_unused=True))\n","        grad_outputs = torch.ones_like(energy)\n","        forces = -torch.autograd.grad(energy, positions, create_graph=True, retain_graph=True, grad_outputs=grad_outputs)[0]     \n","        # 用两种方法算了力，可以确定结果是对的。     \n","        # for i in range(energy.shape[0]): \n","        #     # print(torch.autograd.grad(energy[i], self.positions, create_graph=True)[0][i])\n","        #     forces_1[i] = -torch.autograd.grad(energy[i], positions, retain_graph=True)[0][i] \n","        # assert torch.allclose(forces, forces_1)\n","        return forces, energy\n","    \n","\n","\n","# positions_tensor = torch.from_numpy(positions).to(device=device)\n","# padding_tensor = torch.zeros((n_groups, 1, 3), device=device)\n","# positions_tensor = torch.cat([padding_tensor, positions_tensor], dim=1)\n","# positions_tensor.requires_grad = True\n","model = CustomGraphormerModel(backbone_model).to(device=device)"]},{"cell_type":"code","execution_count":24,"metadata":{"metadata":{}},"outputs":[],"source":["### use for debug\n","\n","# positions_tensor.requires_grad = True\n","\n","# expanded_positions_i = positions_tensor.unsqueeze(2).repeat(1, 1, n_electrons + 1, 1)\n","# expanded_positions_j = positions_tensor.unsqueeze(1).repeat(1, n_electrons + 1, 1, 1)\n","# attn_bias = torch.norm(expanded_positions_i - expanded_positions_j, dim=3)\n","# # attn_bias[0][1][2]\n","# print(\"positions_grad:\", torch.autograd.grad(attn_bias[0][1][2], positions_tensor, create_graph=True)[0])\n","# pred_forces, pred_energy = model(positions_tensor)"]},{"cell_type":"code","execution_count":10,"metadata":{"metadata":{}},"outputs":[{"data":{"text/plain":["tensor([[-0.5855],\n","        [-0.5877],\n","        [-0.5806],\n","        [-0.5816],\n","        [-0.5872],\n","        [-0.5863],\n","        [-0.5845],\n","        [-0.5875],\n","        [-0.5728],\n","        [-0.5861]], device='cuda:0', grad_fn=<AddmmBackward0>)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# pred_energy\n","# potential_energy = torch.from_numpy(potential_energy)\n","# loss = loss_fn(pred_energy[0], potential_energy[0])\n","# loss.backward"]},{"cell_type":"code","execution_count":29,"metadata":{"metadata":{}},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/mamba/envs/hf/lib/python3.8/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["-------------------- Epoch 0 --------------------\n","loss tensor(0.6798, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.6167466   0.35712984 -0.01489629]\n"," [-0.50477359 -0.15899799  0.19152649]\n"," [-0.66885715  0.60097575 -0.42632296]\n"," [ 0.15076018  0.39565822 -0.07277685]\n"," [-0.06851202 -0.72261752  0.11433603]]\n","true force: [[ 1.90920726 -0.56218909  0.44957415]\n"," [-0.61537038 -0.13940708  0.43540062]\n"," [-0.52754575  0.37265249 -0.45870219]\n"," [-0.97053222  1.07116783 -0.41202851]\n"," [ 0.20424109 -0.74222415 -0.01424406]]\n","energy_diff: tensor([2.7803, 1.0911, 1.3028, 2.6425, 2.1139, 2.5288, 1.5649, 1.3781, 0.0000,\n","        1.9802], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 100 --------------------\n","loss tensor(0.6580, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.11296564 -0.33471499  0.16059682]\n"," [ 0.35784871  0.69445203  0.02294121]\n"," [-0.05639638 -0.31858402  0.25019831]\n"," [ 0.06134199 -0.45167513 -0.01688063]\n"," [-0.68794359  0.02340541  0.1546655 ]]\n","true force: [[-6.94099758 -3.1996647  -4.94894665]\n"," [ 0.28091078  0.53791429 -0.14882952]\n"," [ 7.19922208  2.87443362  5.57546159]\n"," [ 0.06512403 -0.38621184 -0.298032  ]\n"," [-0.60425931  0.17352863 -0.17965342]]\n","energy_diff: tensor([0.0000, 1.3601, 1.2096, 1.6798, 0.5915, 1.7447, 0.5542, 2.3920, 1.3244,\n","        2.3904], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 200 --------------------\n","loss tensor(0.3211, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.05080826  0.00806901 -0.03983437]\n"," [-0.31781101 -0.16615955  0.02123084]\n"," [ 0.39666202 -0.09963274  0.07257484]\n"," [-0.06581691  0.03606969 -0.04659269]\n"," [-0.50136486  0.3166436   0.06079436]]\n","true force: [[ 0.69202252 -0.2643249  -0.21092638]\n"," [-0.2117694  -0.33097763  0.11342482]\n"," [ 0.25090396 -0.05593914  0.11793434]\n"," [-0.44208224  0.33180575 -0.27967004]\n"," [-0.28907484  0.31943591  0.25923726]]\n","energy_diff: tensor([1.0100, 0.3336, 0.8250, 0.0000, 0.9437, 0.9640, 1.6184, 1.0416, 0.9738,\n","        1.4671], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 300 --------------------\n","loss tensor(0.6207, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.3062782  -0.01957064  0.21508612]\n"," [ 0.93479041 -0.16528991 -0.78797847]\n"," [ 0.51917164 -0.00402922  1.27088959]\n"," [-0.46094992  0.1388365   0.25866811]\n"," [-0.33204928 -0.04524838  0.20388537]]\n","true force: [[ 0.46651928 -0.01549823 -0.0093923 ]\n"," [ 0.47877814 -0.08962765 -0.53235329]\n"," [ 0.27941899 -0.09543885  0.55892993]\n"," [-1.49717329  4.87337314  0.05983071]\n"," [ 0.27245688 -4.67280841 -0.07701505]]\n","energy_diff: tensor([1.2200, 0.0000, 1.8572, 2.7010, 3.3067, 1.3373, 2.0010, 3.0523, 2.8629,\n","        1.9665], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 400 --------------------\n","loss tensor(0.7965, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.15126807  0.01854218 -0.04906875]\n"," [-0.26894769  0.09694836 -0.07442033]\n"," [-0.24362257  0.50630356 -0.26420741]\n"," [ 0.13014712  0.01594359 -0.06602778]\n"," [-0.1553986   0.02778235 -0.03859349]]\n","true force: [[ 7.36686744  7.50392779  9.29211025]\n"," [-0.33587267  0.15489699 -0.02531204]\n"," [-0.03123598  0.22224298 -0.03959312]\n"," [-6.88255805 -7.49561651 -9.36171034]\n"," [-0.11720075 -0.38545125  0.13450525]]\n","energy_diff: tensor([0.0000, 1.2901, 3.0245, 2.4763, 2.7519, 1.4935, 2.5905, 2.0511, 1.0617,\n","        2.7959], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 500 --------------------\n","loss tensor(0.4792, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.41835643  0.21337166  0.55948237]\n"," [ 0.10909307 -0.75435428 -0.64924203]\n"," [ 0.64386864  0.1910607   0.30011626]\n"," [ 0.22361732 -0.18711487 -0.0896269 ]\n"," [-0.61452693  0.79972249  0.11819071]]\n","true force: [[-0.44245109  0.18761662  0.62417987]\n"," [-0.06554008 -0.49575498 -0.58539122]\n"," [ 0.65852431  0.29456015  0.36768271]\n"," [ 0.43238509 -0.40105272 -0.10795322]\n"," [-0.58291823  0.41463093 -0.29851815]]\n","energy_diff: tensor([2.3891, 2.6210, 2.7433, 2.9705, 2.3380, 0.0000, 2.0666, 2.1001, 2.6177,\n","        2.4962], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 600 --------------------\n","loss tensor(0.6495, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.89064975  0.62449192 -1.27125254]\n"," [-0.00610698  0.53725927  0.89678044]\n"," [ 0.17214011  0.25485854 -0.06770113]\n"," [ 0.13753346  0.20260185 -0.17652695]\n"," [ 0.6345325   0.96555226 -1.88466727]]\n","true force: [[ 4.05148354 -1.22877734  2.67609379]\n"," [-1.80088321 -0.15514741  1.96846024]\n"," [ 3.10650859 -1.07447645  2.7605589 ]\n"," [-1.77019791  0.37381877 -4.11768971]\n"," [-3.58691101  2.08458244 -3.28742322]]\n","energy_diff: tensor([0.0000, 1.8707, 2.7527, 2.1093, 1.9165, 2.8750, 3.4419, 1.7848, 2.5284,\n","        2.2441], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 700 --------------------\n","loss tensor(1.0353, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.00353728  0.72120791 -0.08575537]\n"," [-0.07268994 -0.0343207  -0.90239332]\n"," [ 1.54067369  0.31719331  0.17525644]\n"," [ 0.31564195 -0.57326694  0.39419733]\n"," [-0.67273851 -0.15713318  0.28055505]]\n","true force: [[ 7.47211215e+00  2.44523850e+01 -1.08420561e+01]\n"," [ 2.52824681e-02 -2.98548779e-02 -6.87118833e-01]\n"," [ 7.31009926e-01  4.87570148e-02  3.81645730e-05]\n"," [ 1.91811171e+01 -1.88867887e+01  4.73409021e+00]\n"," [-2.74095217e+01 -5.58449842e+00  6.79504654e+00]]\n","energy_diff: tensor([0.0000, 8.9726, 8.7945, 9.1802, 8.7798, 9.1962, 8.5145, 8.7103, 9.3736,\n","        8.6547], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 800 --------------------\n","loss tensor(0.4017, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.31121816  0.07648529 -0.48611843]\n"," [-0.07017195  0.05452699  0.0137304 ]\n"," [ 0.26757553  0.57648988 -0.36493729]\n"," [-0.30534986 -0.35833902  0.40381009]\n"," [-0.06880694  0.43524866  0.35951339]]\n","true force: [[ 0.52314956 -0.10333688 -0.74465692]\n"," [-0.53592098  0.05551704 -0.18146897]\n"," [ 0.36803795  0.40797831 -0.39443127]\n"," [-0.40215329 -0.71939267  0.58051861]\n"," [ 0.04688675  0.3592342   0.74003856]]\n","energy_diff: tensor([2.3688, 1.5164, 2.7599, 1.9817, 2.8950, 2.6927, 1.9758, 2.5791, 2.2913,\n","        0.0000], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 900 --------------------\n","loss tensor(0.3608, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.17052588  0.1600916   0.26235074]\n"," [ 0.11416982  0.11875288  0.02708491]\n"," [ 0.09021796 -0.0114708  -0.09799981]\n"," [-0.34208698 -0.01085657 -0.32693523]\n"," [-0.01405336 -0.02338305 -0.15149508]]\n","true force: [[-0.04756993  0.02786228  0.92637019]\n"," [ 0.21476978  0.32425544 -0.43611117]\n"," [ 0.60803858 -0.14960194 -0.09434082]\n"," [-0.61035391  0.08977941 -0.07113894]\n"," [-0.16488451 -0.29229518 -0.32477926]]\n","energy_diff: tensor([1.2453, 0.6782, 0.7979, 0.9227, 0.0000, 1.2550, 0.8033, 1.1705, 1.3194,\n","        0.4758], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1000 --------------------\n","loss tensor(1.2749, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.07851111 -0.11811121 -0.03025514]\n"," [-0.07776081  0.05445463 -0.50003988]\n"," [ 0.15050882  0.20475441 -0.07520895]\n"," [ 0.06411301  0.18095302  0.27455298]\n"," [-0.17001994 -0.21343416 -0.00246227]]\n","true force: [[ 0.36995684 -0.5446166   0.14779753]\n"," [-0.37649313  0.3302169  -0.63704538]\n"," [ 0.18782192  0.2817847   0.06348325]\n"," [-0.01277519  0.11999966  0.31566648]\n"," [-0.16851045 -0.18738465  0.11009812]]\n","energy_diff: tensor([6.7639, 6.5111, 0.0000, 6.6569, 6.3270, 4.9135, 6.3671, 6.6856, 6.6371,\n","        5.1708], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1100 --------------------\n","loss tensor(0.6613, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.55947789  0.35268581  0.5642165 ]\n"," [ 0.42043977  0.94838734  0.57084685]\n"," [-0.00317041  0.20816367 -1.00291494]\n"," [ 0.07877525 -0.93460262  0.1934388 ]\n"," [-0.26017288 -0.09309755 -0.12529196]]\n","true force: [[-0.36674077 -0.01910934  0.44288299]\n"," [ 1.30350739  1.7323611   1.4390309 ]\n"," [ 0.10567617  0.82688161 -2.68554681]\n"," [ 0.12453481 -1.90547227  0.99926333]\n"," [-1.1669776  -0.63466111 -0.19563041]]\n","energy_diff: tensor([1.2160, 0.0000, 1.2678, 2.5238, 2.9520, 1.2210, 1.9511, 2.8451, 2.5037,\n","        2.0715], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1200 --------------------\n","loss tensor(0.2604, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.0107897   0.12305316 -0.06539534]\n"," [-0.08961506 -0.28590103 -0.10163906]\n"," [-0.00612623  0.13666843  0.02172165]\n"," [ 0.2422288  -0.11892234  0.15049913]\n"," [-0.23787466  0.15465462 -0.02421343]]\n","true force: [[ 0.05022491  0.22377142 -0.22942102]\n"," [ 0.06432182 -0.42001866 -0.30635709]\n"," [ 0.09210841  0.25195129  0.04149357]\n"," [ 0.27702331 -0.12939213  0.24660618]\n"," [-0.48367845  0.07368808  0.24767836]]\n","energy_diff: tensor([1.3415, 0.3945, 0.0000, 0.8572, 0.9185, 1.1288, 0.8435, 1.7881, 0.8650,\n","        0.9385], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1300 --------------------\n","loss tensor(0.3094, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.72536975 -0.80576359 -0.41253953]\n"," [ 0.1544016   0.03413186  0.00204497]\n"," [-0.53390364 -0.55456728  0.06631538]\n"," [ 0.41541531  0.88770527  0.51469948]\n"," [-0.40183986  1.00157243 -0.01771148]]\n","true force: [[ 0.57083928 -1.04640734 -0.9084655 ]\n"," [ 0.4119015  -0.69723741  0.03237777]\n"," [-0.4241396  -0.51064849  0.11963745]\n"," [ 0.34504788  0.74129969  1.00630312]\n"," [-0.90364906  1.51299355 -0.24985284]]\n","energy_diff: tensor([0.7619, 0.5566, 0.0000, 0.7352, 0.8454, 1.2248, 1.2874, 0.5217, 0.8929,\n","        0.7782], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1400 --------------------\n","loss tensor(0.2829, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-3.29735064e-01  1.36174372e-01  3.14702202e-01]\n"," [-4.56219270e-01  3.98700286e-04 -2.76882800e-01]\n"," [ 8.13204630e-02 -2.81091255e-01 -7.89226510e-02]\n"," [ 5.22656543e-01  3.21907505e-01  1.92932773e-01]\n"," [ 3.16818503e-01 -3.47561029e-01 -6.59025070e-02]]\n","true force: [[-0.32461585  0.09922741  0.76297497]\n"," [-0.80124515  0.33879887 -0.76735445]\n"," [ 0.62693386 -0.45267525 -0.04746073]\n"," [ 0.3008996   0.2898224   0.0777032 ]\n"," [ 0.19802754 -0.27517343 -0.02586299]]\n","energy_diff: tensor([1.5257, 1.5141, 1.0969, 0.7156, 1.2856, 0.7435, 0.0000, 0.4607, 1.4108,\n","        0.4095], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1500 --------------------\n","loss tensor(1.8781, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.81740429 -0.94960123 -1.45524857]\n"," [ 0.2963397  -0.48921929  0.72427493]\n"," [-0.67274903 -1.01746251  1.41822459]\n"," [ 0.83943269  2.44837542 -0.7542222 ]\n"," [ 0.18451074  0.11463327  0.17366777]]\n","true force: [[-3.89281396e-01 -5.19455811e-01 -2.14848917e+00]\n"," [ 2.62744513e+00  4.80884918e-01 -6.65216676e-01]\n"," [-2.99736614e+00 -1.46163773e+00  2.98924553e+00]\n"," [ 2.32850880e-01  1.50109076e+00 -4.98045759e-01]\n"," [ 5.26351521e-01 -8.82142104e-04  3.22506071e-01]]\n","energy_diff: tensor([6.5575, 6.5165, 7.4032, 7.4793, 7.3139, 7.5281, 0.0000, 6.4327, 7.4668,\n","        7.5874], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1600 --------------------\n","loss tensor(0.3029, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.27549393 -0.08625263 -0.29189031]\n"," [-0.54290787  0.14627582  0.31912428]\n"," [ 0.04332289  0.37935889  0.08619571]\n"," [-0.18267683  0.02378965  0.11200427]\n"," [-0.01735099 -0.40746429  0.2256559 ]]\n","true force: [[ 0.22177495  0.01001775 -0.43744565]\n"," [-0.39189043  0.13918961  0.13136675]\n"," [ 0.15461883  0.41297381  0.07489568]\n"," [-0.21589835  0.27755133 -0.30214858]\n"," [ 0.23139501 -0.8397325   0.53333181]]\n","energy_diff: tensor([1.1859, 0.8035, 0.7069, 0.5420, 0.9807, 1.3341, 0.0000, 0.5964, 1.5769,\n","        0.8625], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1700 --------------------\n","loss tensor(0.3570, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.06032875 -0.0736658  -0.46791124]\n"," [-0.11360591 -0.26244597 -0.34586071]\n"," [-0.10797735  0.43735658  0.58587613]\n"," [-0.20054435 -0.0766396  -0.15504075]\n"," [ 0.90047637  0.51089504 -0.01866171]]\n","true force: [[ 2.3368947   1.30984592 -2.81530928]\n"," [-0.10034438 -0.40347174 -0.14275071]\n"," [-0.21370558  0.1891785   0.73600531]\n"," [-2.96577919 -1.33521477  2.16597927]\n"," [ 0.94293445  0.23966209  0.05607541]]\n","energy_diff: tensor([0.0000, 0.9642, 1.5995, 0.0303, 0.9841, 0.3521, 0.9421, 0.7830, 1.1230,\n","        0.8971], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1800 --------------------\n","loss tensor(0.5030, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.4721     -0.28692281 -0.01113392]\n"," [ 0.11340702  0.2450492   0.29557737]\n"," [-0.18268561  0.64377751 -0.36517702]\n"," [ 0.52577845 -0.36158046  0.03212997]\n"," [ 0.40521217  0.16000568  0.0594135 ]]\n","true force: [[-0.52122395 -0.29883719  0.07101255]\n"," [-0.34769837  0.32116035  0.95255017]\n"," [-0.13222004  0.39924738 -0.44122242]\n"," [ 0.35455961 -0.47665213 -0.07115617]\n"," [ 0.64658275  0.05508159 -0.51118413]]\n","energy_diff: tensor([1.6816, 1.4560, 1.5890, 2.2426, 1.5398, 1.7476, 1.8517, 0.0000, 1.9765,\n","        2.0067], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 1900 --------------------\n","loss tensor(0.4592, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.05469824 -0.03602603  0.83829483]\n"," [-0.04460926  0.16101179 -0.23901582]\n"," [-0.09634612  0.97975325  0.08571126]\n"," [ 0.11123155 -0.13246924 -0.14882113]\n"," [-0.25111592 -0.48866227 -0.22254156]]\n","true force: [[ 0.05261446 -0.41334085  1.19111386]\n"," [-0.23747519 -0.34359419 -1.1678971 ]\n"," [ 0.3585356   1.64388707  0.34154694]\n"," [ 0.09791903 -0.15517434 -0.08424595]\n"," [-0.27159389 -0.73177768 -0.28051775]]\n","energy_diff: tensor([2.0072, 1.7042, 2.6229, 2.9064, 2.1534, 2.8093, 0.0000, 2.1260, 2.5058,\n","        1.3482], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 2000 --------------------\n","loss tensor(0.3541, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[ 0.01353919  0.14923992  0.07095276]\n"," [ 0.03435538  0.37567782 -0.30177915]\n"," [-0.00867538 -0.01031917  0.35994489]\n"," [-0.15049113  0.1196701  -0.28213904]\n"," [ 0.02587629 -0.53319705 -0.13827887]]\n","true force: [[-0.09609631  0.25504509  0.21454661]\n"," [ 0.94933905  0.68867152 -0.15141432]\n"," [ 0.02600125 -0.06738761  0.36249265]\n"," [-0.90359809 -0.44520121 -0.29938239]\n"," [ 0.0243541  -0.43112779 -0.12624255]]\n","energy_diff: tensor([1.6217, 0.9853, 1.9128, 1.2045, 1.5411, 1.8240, 0.0000, 0.8831, 1.5407,\n","        1.6101], device='cuda:0', grad_fn=<SubBackward0>) \n","\n","-------------------- Epoch 2100 --------------------\n","loss tensor(0.3730, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","pred_force: [[-0.06186405  0.47562477  0.25414076]\n"," [ 0.46020299  0.02638601  0.33959579]\n"," [ 0.23777405 -0.12822382 -0.4410658 ]\n"," [-0.27092141  0.06737354 -0.09722057]\n"," [-0.06491083 -0.53061895 -0.11153713]]\n","true force: [[-0.17480203  0.54963414  0.25071204]\n"," [ 0.46093892 -0.14492803  0.34979286]\n"," [ 0.41417507 -0.08467303 -0.5167025 ]\n"," [-0.60882592  0.15244736 -0.10132212]\n"," [-0.09148604 -0.47248044  0.01751971]]\n","energy_diff: tensor([1.2133, 0.9748, 0.8861, 0.0000, 1.0249, 0.6375, 1.0197, 0.2647, 1.6297,\n","        0.1560], device='cuda:0', grad_fn=<SubBackward0>) \n","\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","learning_rate = 2e-5\n","parameters = list(model.parameters())\n","optimizer = AdamW(parameters, lr=learning_rate)\n","loss_fn = nn.L1Loss()\n","\n","epochs = 3000\n","for epoch in range(epochs):\n","    epoch_loss = 0\n","    positions, charges = generate_electrons(n_electrons, n_groups)\n","    forces, potential_energy = calculate_forces_and_potential(positions, charges)\n","    potential_energy = torch.from_numpy(potential_energy).to(device=device, dtype=torch.float32)\n","    \n","    positions = torch.from_numpy(positions).to(device=device)\n","    padding_tensor = torch.zeros((n_groups, 1, 3), device=device)\n","    positions_tensor = torch.cat([padding_tensor, positions], dim=1).to(device=device)\n","    positions_tensor.requires_grad = True\n","    pred_forces, pred_energy = model(positions_tensor)\n","    pred_energy = pred_energy.squeeze()\n","\n","    ### use energy to train ###\n","    # loss = loss_fn(pred_energy, potential_energy).to(device=device)\n","    ### use force to train ###\n","    loss = loss_fn(pred_forces[:, 1:], torch.from_numpy(forces).to(device=device))\n","    optimizer.zero_grad()\n","    loss.backward(retain_graph=True)\n","    optimizer.step()\n","    \n","    if epoch % 100 == 0:\n","        print(\"-\"*20, \"Epoch\", epoch, \"-\"*20)\n","        print(\"loss\", loss)\n","        print(\"pred_force:\", pred_forces[0,1:].cpu().detach().numpy())\n","        print(\"true force:\", forces[0])\n","        # 当用导数作为损失的时候，原函数可能会相差一个常数。\n","        print(\"energy_diff:\", pred_energy-potential_energy-min(pred_energy-potential_energy), \"\\n\")\n","        # print(\"true energy:\", potential_energy, \"\\n\")\n","print(\"pred_energy:\", pred_energy)\n","print(\"true energy:\", potential_energy)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([7.6923, 7.6951, 7.7410, 7.9025, 7.7520, 7.7880, 8.3276, 7.6907, 7.6142,\n","        8.0990], grad_fn=<SubBackward0>)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["potential_energy - pred_energy"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["(array([[ 0.14452395,  0.3603397 ,  0.08955894],\n","        [-0.09670379,  0.42073898, -0.99655067],\n","        [-0.68156128,  0.32000283,  0.55275471],\n","        [ 0.10994643, -0.68132027, -0.66032615],\n","        [ 0.45297355, -0.26133985,  0.47834905]]),\n"," array([[ 0.92717188,  0.27600466,  0.80216212],\n","        [-0.75420111,  0.59891876, -1.3950508 ],\n","        [-0.58388106,  0.07083495,  0.47482792],\n","        [-0.05501321, -0.75061304, -0.62454082],\n","        [ 0.46592351, -0.19514533,  0.74260158]]))"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["pred_forces[0, 1:].detach().numpy(), forces[0]"]}],"metadata":{"kernelspec":{"display_name":"huggingface","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":2}
